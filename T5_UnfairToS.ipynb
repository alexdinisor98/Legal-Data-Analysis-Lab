{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7u9sdPLQrl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install sentencepiece\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_hgM0D9Ty6Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kIT8igyT5Ti"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QViSrP03aFpa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMlOYMIaVH7I"
      },
      "outputs": [],
      "source": [
        "id2label = {0 : \"Limitation of liability\",\n",
        "           1 : \"Unilateral termination\",\n",
        "           2: \"Unilateral change\",\n",
        "           3: \"Content removal\",\n",
        "           4: \"Contract by using\",\n",
        "           5: \"Choice of law\",\n",
        "           6: \"Jurisdiction\",\n",
        "           7: \"Arbitration\", }          \n",
        "\n",
        "label2id = {v: k for k, v in id2label.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUn1-KudUiQq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, list_datasets\n",
        "dataset = load_dataset(\"lex_glue\", 'unfair_tos')\n",
        "\n",
        "df_all = pd.DataFrame()\n",
        "df_train = pd.DataFrame()\n",
        "df_val = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "df_train = pd.read_csv('/content/train_alphabetical.csv')\n",
        "for index, row in df_train.iterrows():\n",
        "     label_string = row['labels'].split(',')\n",
        "     row_string_label_list = []\n",
        "     for l in label_string:\n",
        "        l = l.strip()\n",
        "        row_string_label_list.append(label2id[l])\n",
        "\n",
        "     row['labels'] = row_string_label_list\n",
        "\n",
        "for row in dataset['validation']:\n",
        "    df_all = df_all.append(row, ignore_index=True)\n",
        "    if not row['labels']:\n",
        "      row['labels'].append(8)\n",
        "    df_val = df_val.append(row, ignore_index=True)\n",
        "\n",
        "for row in dataset['test']:\n",
        "    df_all = df_all.append(row, ignore_index=True)\n",
        "    if not row['labels']:\n",
        "      row['labels'].append(8)\n",
        "    df_test = df_test.append(row, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(35)"
      ],
      "metadata": {
        "id": "IHEyRQbO8v53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head(35)"
      ],
      "metadata": {
        "id": "midtUdcX7BXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMxyAxMFUlgb"
      },
      "outputs": [],
      "source": [
        "# # get frequency of labels\n",
        "# import collections, itertools\n",
        "\n",
        "# list_labelslist = df_train['labels'].tolist()\n",
        "# freq = collections.defaultdict(int)  # 0 by default\n",
        "# for x in itertools.chain.from_iterable(list_labelslist):\n",
        "#     freq[x] += 1\n",
        "\n",
        "# sorted_label_freq = dict(sorted(freq.items(), key=lambda item: item[1], reverse=True))\n",
        "# sorted_label_freq = list(sorted_label_freq.keys())\n",
        "# sorted_label_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFO1XSGVUoKD"
      },
      "outputs": [],
      "source": [
        "# # reorder labels in train set by frequency\n",
        "# for index, row in df_train.iterrows():\n",
        "#   label_list = row['labels']\n",
        "#   if len(label_list) > 1:\n",
        "#     row['labels'] = sorted(label_list, key=lambda x: sorted_label_freq.index(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BBYQ7wjUFEB"
      },
      "outputs": [],
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len, SUMMARY_LEN):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = df\n",
        "        self.text = df['text']\n",
        "        self.max_len = max_len\n",
        "        self.labels_len = SUMMARY_LEN\n",
        "\n",
        "        self.labels = []\n",
        "        for label_pair in df['labels']:\n",
        "            row_string_label_list = []\n",
        "            for l in label_pair:\n",
        "                row_string_label_list.append(id2label[l])\n",
        "            self.labels.append(row_string_label_list)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        labelstostring = \", \".join(labels)\n",
        "        labelstostring = 'summarize: ' + labelstostring\n",
        "\n",
        "        source = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        target = self.tokenizer(\n",
        "            labelstostring, \n",
        "            max_length=self.labels_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "            )\n",
        "        \n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_mask.to(dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwe2LXmaUQDJ"
      },
      "outputs": [],
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            print(\"Training Loss: \", loss.item())\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91-7XxmIUScD"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=10, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10h8eZ_XUZcQ"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training  \n",
        "TRAIN_BATCH_SIZE = 128    # input batch size for training (default: 64)\n",
        "VALID_BATCH_SIZE = 128    # input batch size for testing (default: 1000)\n",
        "TRAIN_EPOCHS = 20        # number of epochs to train (default: 10)\n",
        "VAL_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "SEED = 42               # random seed (default: 42)\n",
        "MAX_LEN = 32\n",
        "SUMMARY_LEN = 10 \n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(SEED) # pytorch random seed\n",
        "np.random.seed(SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(df_train, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "validation_set = CustomDataset(df_val, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "test_set = CustomDataset(df_test, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df_all.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(df_train.shape))\n",
        "print(\"VAL Dataset: {}\".format(df_val.shape))\n",
        "print(\"TEST Dataset: {}\".format(df_test.shape))\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(validation_set, **val_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co7KFpEwXxnp"
      },
      "outputs": [],
      "source": [
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "for epoch in range(VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'pred':predictions,'true':actuals})\n",
        "    final_df.to_csv('/content/sample_data/predictions.csv')\n",
        "    print('Output Files generated for review')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swylYbLucZLP"
      },
      "outputs": [],
      "source": [
        "final_df.head(150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWywa5Nk_LwI"
      },
      "source": [
        "## Clean Outputs\n",
        "i.e. Remove the string 'summarize:' in target ouputs + Keep only labels strings in prediction outputs. \n",
        "\n",
        "For example: ': Unilateral change' -> 'Unilateral change', 'summarize: No violation' -> 'No violation'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4h4UdjV55i-"
      },
      "outputs": [],
      "source": [
        "def clean_pred(row_pred):\n",
        "  cleaned_pred = ''\n",
        "  for predefined_label in list(id2label.values()):\n",
        "    if str(row_pred).find(predefined_label) > -1:\n",
        "      cleaned_pred += predefined_label + ', '\n",
        "  return cleaned_pred.split(',')[0]\n",
        "\n",
        "final_df['pred'] = final_df['pred'].apply(clean_pred)\n",
        "\n",
        "final_df['true'] = final_df['true'].apply(lambda x: x.split('summarize: ')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Q2p5KDF46b"
      },
      "outputs": [],
      "source": [
        "final_df.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulaIIQ03G_Ib"
      },
      "source": [
        "##Evaluate performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzw0QWvwwM74"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "val_preds = final_df['pred'].to_numpy()\n",
        "val_targets = final_df['true'].to_numpy()\n",
        "\n",
        "f1_score_micro = metrics.f1_score(val_targets, val_preds, average='micro')\n",
        "f1_score_macro = metrics.f1_score(val_targets, val_preds, average='macro')\n",
        "\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in list(id2label.values()):\n",
        "  copy_df = final_df[final_df.true == label]\n",
        "\n",
        "  test_preds = copy_df['pred'].to_numpy()\n",
        "  test_targets = copy_df['true'].to_numpy()\n",
        "\n",
        "  f1_score_micro = metrics.f1_score(test_targets, test_preds, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(test_targets, test_preds, average='macro')\n",
        "  print(f\"F1 Score (Micro) {label} = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) {label} = {f1_score_macro}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "BgABDS9RxZgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "T5_UnfairToS.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}