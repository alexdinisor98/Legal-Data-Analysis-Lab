{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80fp6domOYxE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl71J4bKc4Xk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjoeTd8LJFQ5"
      },
      "outputs": [],
      "source": [
        "UNFAIR_CATEGORIES = [\n",
        "    \"Limitation of liability\",\n",
        "    \"Unilateral termination\",\n",
        "    \"Unilateral change\",\n",
        "    \"Content removal\",\n",
        "    \"Contract by using\",\n",
        "    \"Choice of law\",\n",
        "    \"Jurisdiction\",\n",
        "    \"Arbitration\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oACdTcbRHNdP"
      },
      "source": [
        "## Create UnfairToS dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk6Wpup5H2fM"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, list_datasets\n",
        "dataset = load_dataset(\"lex_glue\", 'unfair_tos')\n",
        "\n",
        "df_all = pd.DataFrame()\n",
        "df_train = pd.DataFrame()\n",
        "df_val = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "for row in dataset['train']:\n",
        "    df_all = df_all.append(row, ignore_index=True)\n",
        "    df_train = df_train.append(row, ignore_index=True)\n",
        "\n",
        "for row in dataset['validation']:\n",
        "    df_all = df_all.append(row, ignore_index=True)\n",
        "    df_val = df_val.append(row, ignore_index=True)\n",
        "\n",
        "for row in dataset['test']:\n",
        "    df_all = df_all.append(row, ignore_index=True)\n",
        "    df_test = df_test.append(row, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEAPWR-sHrfO"
      },
      "outputs": [],
      "source": [
        "df_train.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DC9mybHSzq2"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiL9rAUTS9Xf"
      },
      "outputs": [],
      "source": [
        "example_text = df_train.iloc[0]['text']\n",
        "bert_input = tokenizer(example_text,padding='max_length', max_length=50, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids']) # id representation of each token 101=CLS, 4430=notice etc.\n",
        "print(bert_input['token_type_ids']) # in which sequence a token belongs\n",
        "print(bert_input['attention_mask']) # whether a token is a real word or just padding: [CLS], [SEP], word = 1 else 0 ([PAD])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4PedEltU1FJ"
      },
      "outputs": [],
      "source": [
        "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "\n",
        "print(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D13TGIXqSZRN"
      },
      "outputs": [],
      "source": [
        "enc_labels = {0 : \"Limitation of liability\",\n",
        "           1 : \"Unilateral termination\",\n",
        "           2: \"Unilateral change\",\n",
        "           3: \"Content removal\",\n",
        "           4: \"Contract by using\",\n",
        "           5: \"Choice of law\",\n",
        "           6: \"Jurisdiction\",\n",
        "           7: \"Arbitration\", \n",
        "          }\n",
        "\n",
        "labels = []\n",
        "for label_pair in df_train['labels']:\n",
        "    row_encodings_list = []\n",
        "    for l in enc_labels.keys():\n",
        "        if l in label_pair:\n",
        "            row_encodings_list.append(1)\n",
        "        else:\n",
        "            row_encodings_list.append(0)\n",
        "    # # NO_TYPE \n",
        "    # if not label_pair:\n",
        "    #     row_encodings_list.append(1)\n",
        "    # else:\n",
        "    #     row_encodings_list.append(0)\n",
        "\n",
        "    labels.append(row_encodings_list)\n",
        "\n",
        "print(labels)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5k2CbDIOGHR"
      },
      "outputs": [],
      "source": [
        "labels_df_train = pd.DataFrame.from_records(labels, columns=[\"Limitation of liability\", \"Unilateral termination\", \"Unilateral change\", \"Content removal\", \"Contract by using\", \"Choice of law\", \"Jurisdiction\", \"Arbitration\"])\n",
        "LABEL_COLUMNS = labels_df_train.columns.tolist()\n",
        "labels_df_train[LABEL_COLUMNS].sum().sort_values()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(labels))"
      ],
      "metadata": {
        "id": "59tyTSyV25nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V50kwp-FGk_e"
      },
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxDz9tq6t8U1"
      },
      "outputs": [],
      "source": [
        "label2id = {\"Limitation of liability\": 0,\n",
        "          \"Unilateral termination\": 1,\n",
        "          \"Unilateral change\": 2,\n",
        "          \"Content removal\": 3,\n",
        "          \"Contract by using\": 4,\n",
        "          \"Choice of law\": 5,\n",
        "          \"Jurisdiction\": 6,\n",
        "          \"Arbitration\": 7, \n",
        "          }\n",
        "\n",
        "id2label = {0: \"Limitation of liability\",\n",
        "          1: \"Unilateral termination\",\n",
        "          2: \"Unilateral change\",\n",
        "          3: \"Content removal\",\n",
        "          4: \"Contract by using\",\n",
        "          5: \"Choice of law\",\n",
        "          6: \"Jurisdiction\",\n",
        "          7: \"Arbitration\", \n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBrzdDY6Gu6B"
      },
      "outputs": [],
      "source": [
        "enc_labels = {0 : \"Limitation of liability\",\n",
        "           1 : \"Unilateral termination\",\n",
        "           2: \"Unilateral change\",\n",
        "           3: \"Content removal\",\n",
        "           4: \"Contract by using\",\n",
        "           5: \"Choice of law\",\n",
        "           6: \"Jurisdiction\",\n",
        "           7: \"Arbitration\", \n",
        "          }\n",
        "\n",
        "'''\n",
        "        self.labels = []\n",
        "        for label_pair in df['label']:\n",
        "          row_encodings_list = []\n",
        "          for l in label_pair:\n",
        "            row_encodings_list.append(enc_labels[l])\n",
        "          self.labels.append(row_encodings_list)\n",
        "'''\n",
        "        \n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = df\n",
        "        self.text = df['text']\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.targets = []\n",
        "        for label_pair in df['labels']:\n",
        "            row_encodings_list = []\n",
        "            for l in enc_labels.keys():\n",
        "                if l in label_pair:\n",
        "                    row_encodings_list.append(1)\n",
        "                else:\n",
        "                    row_encodings_list.append(0)\n",
        "\n",
        "            self.targets.append(row_encodings_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4akmAOFhbhJa"
      },
      "outputs": [],
      "source": [
        "# Config\n",
        "MAX_LEN = 64\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "VALID_BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWA-hSq-cBv9"
      },
      "source": [
        "## Train:Val:Test Shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPvA0vgyb0lq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"zlucia/custom-legalbert\")\n",
        "\n",
        "training_set = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
        "validation_set = CustomDataset(df_val, tokenizer, MAX_LEN)\n",
        "test_set = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df_all.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(df_train.shape))\n",
        "print(\"VAL Dataset: {}\".format(df_val.shape))\n",
        "print(\"TEST Dataset: {}\".format(df_test.shape))\n",
        "print(df_train.shape[0] + df_val.shape[0] + df_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN6LzT6mfACv"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "validation_loader = DataLoader(validation_set, **val_params)\n",
        "test_loader = DataLoader(test_set, **test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTogwvPGMjwv"
      },
      "source": [
        "## BERT Model Buidling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNdo2PvNMiso"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel, AutoModel\n",
        "\n",
        "# *-base configuration of each pre-trained model, \n",
        "# i.e., 12 Transformer blocks, 768 hidden units (DEFAULT), \n",
        "# and 12 attention heads (DEFAULT). We train models with the Adam optimizer \n",
        "# and an initial learning rate of 3e-5 up to 20 epochs \n",
        "# using early stopping on development data. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "        # self.l1 = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "        # self.l1 = AutoModel.from_pretrained(\"zlucia/custom-legalbert\")\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 8)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        # _ = embedding vector of tokens\n",
        "        # pooled_output = embedding vector of [CLS] token\n",
        "        _, pooled_output= self.l1(input_ids=ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        dropout_output = self.l2(pooled_output)\n",
        "        linear_output = self.l3(dropout_output)\n",
        "\n",
        "        return linear_output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOedLXnf45P"
      },
      "source": [
        "Save the best model during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMo8FK2Pf0N2"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeXLxGuMfx44"
      },
      "outputs": [],
      "source": [
        "import shutil, sys   \n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fulcTzJAfp53"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnCDb7O_P-aL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# EPOCHS = 20\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    weights = torch.tensor([0.2, 0.3, 0.35, 0.5, 0.55, 0.7, 0.75, 0.8]).to(device)\n",
        "\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs.to(device), targets.to(device))\n",
        "\n",
        "\n",
        "params = {\n",
        "    'lr': [3e-5, 1e-5, 3e-4, 1e-4, 3e-3, 3e-2]\n",
        "}\n",
        "LEARNING_RATE = 3e-4\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DH3vnNkftNq"
      },
      "outputs": [],
      "source": [
        "val_targets = []\n",
        "val_outputs = []\n",
        "\n",
        "def train_model(start_epochs,  n_epochs, valid_loss_min_input, \n",
        "                training_loader, validation_loader, model, \n",
        "                optimizer, checkpoint_path, best_model_path):\n",
        "   \n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = valid_loss_min_input \n",
        "  \n",
        "  for epoch in range(start_epochs, n_epochs + 1):\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "    for batch_idx, data in enumerate(training_loader):\n",
        "        #print('yyy epoch', batch_idx)\n",
        "        ids = data['ids'].to(device='cuda', dtype = torch.long)\n",
        "        mask = data['mask'].to(device='cuda', dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device='cuda', dtype = torch.long)\n",
        "        targets = data['targets'].to(device='cuda', dtype = torch.float)\n",
        "        \n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('before loss data in training', loss.item(), train_loss)\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        #print('after loss data in training', loss.item(), train_loss)\n",
        "    \n",
        "    print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "    \n",
        "    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        " \n",
        "    model.eval()\n",
        "   \n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(validation_loader, 0):\n",
        "            ids = data['ids'].to(device='cuda', dtype = torch.long)\n",
        "            mask = data['mask'].to(device='cuda', dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device='cuda', dtype = torch.long)\n",
        "            targets = data['targets'].to(device='cuda', dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "            val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "      print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "      # calculate average losses\n",
        "      #print('before cal avg train loss', train_loss)\n",
        "      train_loss = train_loss/len(training_loader)\n",
        "      valid_loss = valid_loss/len(validation_loader)\n",
        "      # print training/validation statistics \n",
        "      print('Epoch: {} \\tAverage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "      \n",
        "\n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "        \n",
        "      # save checkpoint\n",
        "      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "        \n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs_NPUMdgRMI"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = '/content/current_checkpoint.pt'\n",
        "best_model = '/content/best_model.pt'\n",
        "\n",
        "# early stopping patience; how long to wait after last time validation loss improved.\n",
        "patience = 3\n",
        "model = model.to(device)\n",
        "trained_model = train_model(1, \n",
        "                            20, \n",
        "                            np.Inf, \n",
        "                            training_loader, \n",
        "                            validation_loader, \n",
        "                            model, optimizer, \n",
        "                            checkpoint_path, \n",
        "                            best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFDaC62bkMEK"
      },
      "outputs": [],
      "source": [
        "val_preds = (np.array(val_outputs) > 0.5).astype(int)\n",
        "val_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhjKriDbdlkf"
      },
      "outputs": [],
      "source": [
        "preds_df = pd.DataFrame(val_preds, columns = UNFAIR_CATEGORIES) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8S6vWvxfkZx"
      },
      "outputs": [],
      "source": [
        "df_concat = pd.concat([df_val, preds_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUnxcvSKkLPj"
      },
      "outputs": [],
      "source": [
        "accuracy = metrics.accuracy_score(val_targets, val_preds)\n",
        "f1_score_micro = metrics.f1_score(val_targets, val_preds, average='micro')\n",
        "f1_score_macro = metrics.f1_score(val_targets, val_preds, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8vI_vzafPtT"
      },
      "outputs": [],
      "source": [
        "test_targets = []\n",
        "test_outputs = []\n",
        "\n",
        "def test(device, model, test_loader):\n",
        "    # Settings\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(test_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            # loss = loss_fn(outputs, targets)\n",
        "            # valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "            test_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            test_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzJefcnmfxJI"
      },
      "outputs": [],
      "source": [
        "test(device, model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx08FazmhrSr"
      },
      "outputs": [],
      "source": [
        "test_preds = (np.array(test_outputs) > 0.5).astype(float)\n",
        "test_preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "test_targets = numpy.array(test_targets)\n",
        "test_targets_ext = np.zeros((test_targets.shape[0], test_targets.shape[1] + 1), dtype=np.float)\n",
        "test_targets_ext[:, :-1] = test_targets\n",
        "test_targets_ext[:, -1] = (np.sum(test_targets, axis=1) == 0).astype(float)\n",
        "test_targets_ext.shape\n",
        "test_targets_ext"
      ],
      "metadata": {
        "id": "dRYblOcU5tM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_targets = numpy.array(test_targets)\n",
        "test_preds_ext = np.zeros((test_preds.shape[0], test_preds.shape[1] + 1), dtype=np.float)\n",
        "test_preds_ext[:, :-1] = test_preds\n",
        "test_preds_ext[:, -1] = (np.sum(test_preds, axis=1) == 0).astype(float)\n",
        "test_preds_ext.shape\n",
        "test_preds_ext"
      ],
      "metadata": {
        "id": "qxK_G7P1utzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmSivN8Jhwxq"
      },
      "outputs": [],
      "source": [
        "accuracy = metrics.accuracy_score(test_targets_ext, test_preds_ext)\n",
        "f1_score_micro = metrics.f1_score(test_targets_ext, test_preds_ext, average='micro')\n",
        "f1_score_macro = metrics.f1_score(test_targets_ext, test_preds_ext, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VMWEal_kUxB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpeIn0M5kYez"
      },
      "outputs": [],
      "source": [
        "cm = mcm(val_targets, val_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-gTNw2jkx40"
      },
      "outputs": [],
      "source": [
        "print(classification_report(val_targets, val_preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "UnfairToS_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}